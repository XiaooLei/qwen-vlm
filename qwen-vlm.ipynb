{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628d45c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:01.920686Z",
     "iopub.status.busy": "2026-02-01T14:20:01.920437Z",
     "iopub.status.idle": "2026-02-01T14:20:03.121926Z",
     "shell.execute_reply": "2026-02-01T14:20:03.121249Z"
    },
    "papermill": {
     "duration": 1.206445,
     "end_time": "2026-02-01T14:20:03.123492",
     "exception": false,
     "start_time": "2026-02-01T14:20:01.917047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'qwen-vlm'...\r\n",
      "remote: Enumerating objects: 150, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (150/150), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (108/108), done.\u001b[K\r\n",
      "remote: Total 150 (delta 90), reused 95 (delta 41), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (150/150), 45.23 KiB | 5.03 MiB/s, done.\r\n",
      "Resolving deltas: 100% (90/90), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/XiaooLei/qwen-vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7452f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:03.129589Z",
     "iopub.status.busy": "2026-02-01T14:20:03.129136Z",
     "iopub.status.idle": "2026-02-01T14:20:03.135190Z",
     "shell.execute_reply": "2026-02-01T14:20:03.134595Z"
    },
    "papermill": {
     "duration": 0.010532,
     "end_time": "2026-02-01T14:20:03.136459",
     "exception": false,
     "start_time": "2026-02-01T14:20:03.125927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/qwen-vlm\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/qwen-vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0379c86e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:03.142057Z",
     "iopub.status.busy": "2026-02-01T14:20:03.141493Z",
     "iopub.status.idle": "2026-02-01T14:20:10.276767Z",
     "shell.execute_reply": "2026-02-01T14:20:10.276083Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.139796,
     "end_time": "2026-02-01T14:20:10.278472",
     "exception": false,
     "start_time": "2026-02-01T14:20:03.138676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 2)) (4.57.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 3)) (4.67.1)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 4)) (11.3.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 5)) (2.32.5)\r\n",
      "Collecting datasets==2.14.0 (from -r /kaggle/working/qwen-vlm/requirements.txt (line 6))\r\n",
      "  Downloading datasets-2.14.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 7)) (0.36.0)\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 8)) (1.11.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /kaggle/working/qwen-vlm/requirements.txt (line 9)) (2.0.2)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (22.0.0)\r\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6))\r\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2.2.2)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (0.70.18)\r\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2025.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (3.13.3)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (26.0rc2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (6.0.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (3.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (3.4.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 2)) (2025.11.3)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 2)) (0.22.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 2)) (0.6.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r /kaggle/working/qwen-vlm/requirements.txt (line 5)) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r /kaggle/working/qwen-vlm/requirements.txt (line 5)) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r /kaggle/working/qwen-vlm/requirements.txt (line 5)) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r /kaggle/working/qwen-vlm/requirements.txt (line 5)) (2026.1.4)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /kaggle/working/qwen-vlm/requirements.txt (line 7)) (1.2.1rc0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r /kaggle/working/qwen-vlm/requirements.txt (line 8)) (5.9.5)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (1.22.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 1)) (3.0.3)\r\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting multiprocess (from datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6))\r\n",
      "  Downloading multiprocess-0.70.19-py312-none-any.whl.metadata (7.5 kB)\r\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\r\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\r\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.0->-r /kaggle/working/qwen-vlm/requirements.txt (line 6)) (1.17.0)\r\n",
      "Downloading datasets-2.14.0-py3-none-any.whl (492 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: dill, multiprocess, datasets\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.4.0\r\n",
      "    Uninstalling dill-0.4.0:\r\n",
      "      Successfully uninstalled dill-0.4.0\r\n",
      "  Attempting uninstall: multiprocess\r\n",
      "    Found existing installation: multiprocess 0.70.18\r\n",
      "    Uninstalling multiprocess-0.70.18:\r\n",
      "      Successfully uninstalled multiprocess-0.70.18\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 4.4.2\r\n",
      "    Uninstalling datasets-4.4.2:\r\n",
      "      Successfully uninstalled datasets-4.4.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\r\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed datasets-2.14.0 dill-0.3.7 multiprocess-0.70.15\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /kaggle/working/qwen-vlm/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f237726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:10.286850Z",
     "iopub.status.busy": "2026-02-01T14:20:10.286250Z",
     "iopub.status.idle": "2026-02-01T14:20:10.718278Z",
     "shell.execute_reply": "2026-02-01T14:20:10.717552Z"
    },
    "papermill": {
     "duration": 0.43783,
     "end_time": "2026-02-01T14:20:10.719812",
     "exception": false,
     "start_time": "2026-02-01T14:20:10.281982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/XiaooLei/qwen-vlm\r\n",
      " * branch            main       -> FETCH_HEAD\r\n",
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b59dd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:10.728488Z",
     "iopub.status.busy": "2026-02-01T14:20:10.727891Z",
     "iopub.status.idle": "2026-02-01T14:20:10.852850Z",
     "shell.execute_reply": "2026-02-01T14:20:10.852110Z"
    },
    "papermill": {
     "duration": 0.131047,
     "end_time": "2026-02-01T14:20:10.854482",
     "exception": false,
     "start_time": "2026-02-01T14:20:10.723435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 挂一个软连接\n",
    "!ln -sf /kaggle/input/llava-data-10000/llava_data /kaggle/working/qwen-vlm/llava_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bb5e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:20:10.862483Z",
     "iopub.status.busy": "2026-02-01T14:20:10.862256Z",
     "iopub.status.idle": "2026-02-01T16:45:48.145723Z",
     "shell.execute_reply": "2026-02-01T16:45:48.145031Z"
    },
    "papermill": {
     "duration": 8737.289551,
     "end_time": "2026-02-01T16:45:48.147522",
     "exception": false,
     "start_time": "2026-02-01T14:20:10.857971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-01 14:20:34.240539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1769955634.551423      71 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1769955634.637550      71 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1769955635.440111      71 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769955635.440170      71 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769955635.440178      71 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769955635.440184      71 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "tokenizer_config.json: 7.30kB [00:00, 28.8MB/s]\r\n",
      "vocab.json: 2.78MB [00:00, 83.2MB/s]\r\n",
      "merges.txt: 1.67MB [00:00, 139MB/s]\r\n",
      "tokenizer.json: 7.03MB [00:00, 188MB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 659/659 [00:00<00:00, 5.17MB/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 988M/988M [00:03<00:00, 328MB/s]\r\n",
      "generation_config.json: 100%|██████████████████| 242/242 [00:00<00:00, 2.39MB/s]\r\n",
      "config.json: 4.10kB [00:00, 20.2MB/s]\r\n",
      "pytorch_model.bin: 100%|██████████████████████| 599M/599M [00:03<00:00, 161MB/s]\r\n",
      "preprocessor_config.json: 100%|████████████████| 316/316 [00:00<00:00, 3.05MB/s]\r\n",
      "检测到占位符序列: [27, 1805, 29] (长度: 3)\r\n",
      "Qwen/Qwen2.5-0.5B-Instruct LLM hidden dim: 896\r\n",
      "tokenizer_config.json: 7.23kB [00:00, 33.0MB/s]\r\n",
      "model.safetensors:   0%|                             | 0.00/599M [00:00<?, ?B/s]\r\n",
      "vocab.json: 2.78MB [00:00, 150MB/s]\r\n",
      "\r\n",
      "merges.txt: 1.67MB [00:00, 150MB/s]\r\n",
      "\r\n",
      "tokenizer.json: 7.03MB [00:00, 105MB/s]\r\n",
      "model.safetensors: 100%|█████████████████████| 599M/599M [00:09<00:00, 61.8MB/s]\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Epoch 0:  11%|████▋                                        | 526/5000 [05:04<42:44,  1.74it/s, loss=1.4945, lr=1.08e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000244844.jpg: cannot identify image file './llava_data/train2017/000000244844.jpg'\r\n",
      "Epoch 0:  37%|████████████████▍                           | 1864/5000 [17:50<29:56,  1.75it/s, loss=1.5378, lr=1.28e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000220408.jpg: cannot identify image file './llava_data/train2017/000000220408.jpg'\r\n",
      "Epoch 0:  49%|█████████████████████▌                      | 2448/5000 [23:24<24:19,  1.75it/s, loss=1.4464, lr=1.37e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Epoch 0:  71%|███████████████████████████████▏            | 3548/5000 [33:54<13:51,  1.75it/s, loss=1.5908, lr=1.53e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000354734.jpg: cannot identify image file './llava_data/train2017/000000354734.jpg'\r\n",
      "Epoch 0:  87%|██████████████████████████████████████▏     | 4345/5000 [41:31<06:15,  1.75it/s, loss=1.7019, lr=1.65e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000166762.jpg: cannot identify image file './llava_data/train2017/000000166762.jpg'\r\n",
      "Epoch 0: 100%|████████████████████████████████████████████| 5000/5000 [47:46<00:00,  1.74it/s, loss=1.5850, lr=1.75e-05]\r\n",
      "Evaluating Epoch 0:   0%|                                                                        | 0/50 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Evaluating Epoch 0:  86%|██████████████████████████████████████████████████████▏        | 43/50 [00:12<00:02,  3.43it/s]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Evaluating Epoch 0: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.39it/s]\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Epoch 1:   0%|                                                                                 | 0/5000 [00:00<?, ?it/s]\r\n",
      "✅ 检查成功: Loss grad_fn = <DivBackward0 object at 0x7c779f8bbf40>\r\n",
      "Epoch 1:   3%|█▍                                           | 162/5000 [01:32<46:16,  1.74it/s, loss=1.6618, lr=1.77e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000244844.jpg: cannot identify image file './llava_data/train2017/000000244844.jpg'\r\n",
      "Epoch 1:  27%|███████████▉                                | 1356/5000 [12:57<34:47,  1.75it/s, loss=1.4172, lr=1.95e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000166762.jpg: cannot identify image file './llava_data/train2017/000000166762.jpg'\r\n",
      "Epoch 1:  36%|███████████████▊                            | 1790/5000 [17:05<30:43,  1.74it/s, loss=1.5604, lr=2.02e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000354734.jpg: cannot identify image file './llava_data/train2017/000000354734.jpg'\r\n",
      "Epoch 1:  47%|████████████████████▍                       | 2328/5000 [22:14<25:31,  1.74it/s, loss=1.5474, lr=2.10e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000220408.jpg: cannot identify image file './llava_data/train2017/000000220408.jpg'\r\n",
      "Epoch 1:  69%|██████████████████████████████▍             | 3453/5000 [32:58<14:47,  1.74it/s, loss=1.4354, lr=2.27e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Epoch 1: 100%|████████████████████████████████████████████| 5000/5000 [47:45<00:00,  1.74it/s, loss=1.4739, lr=2.50e-05]\r\n",
      "Evaluating Epoch 1:   0%|                                                                        | 0/50 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Evaluating Epoch 1:  86%|██████████████████████████████████████████████████████▏        | 43/50 [00:12<00:02,  3.42it/s]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Evaluating Epoch 1: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.38it/s]\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Epoch 2:  24%|██████████▎                                 | 1178/5000 [11:15<36:32,  1.74it/s, loss=1.4697, lr=2.68e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Epoch 2:  37%|████████████████▏                           | 1833/5000 [17:30<30:13,  1.75it/s, loss=1.4185, lr=2.77e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000166762.jpg: cannot identify image file './llava_data/train2017/000000166762.jpg'\r\n",
      "Epoch 2:  52%|██████████████████████▋                     | 2576/5000 [24:36<23:08,  1.75it/s, loss=1.4268, lr=2.89e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000220408.jpg: cannot identify image file './llava_data/train2017/000000220408.jpg'\r\n",
      "Epoch 2:  87%|██████████████████████████████████████▏     | 4343/5000 [41:28<06:16,  1.74it/s, loss=1.4421, lr=3.15e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000354734.jpg: cannot identify image file './llava_data/train2017/000000354734.jpg'\r\n",
      "Epoch 2: 100%|███████████████████████████████████████████▊| 4984/5000 [47:36<00:09,  1.74it/s, loss=1.5243, lr=3.25e-05]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000244844.jpg: cannot identify image file './llava_data/train2017/000000244844.jpg'\r\n",
      "Epoch 2: 100%|████████████████████████████████████████████| 5000/5000 [47:45<00:00,  1.74it/s, loss=1.4798, lr=3.25e-05]\r\n",
      "Evaluating Epoch 2:   0%|                                                                        | 0/50 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n",
      "Evaluating Epoch 2:  86%|██████████████████████████████████████████████████████▏        | 43/50 [00:12<00:02,  3.42it/s]WARNING:data_set:无法打开图片 ./llava_data/train2017/000000219735.jpg: cannot identify image file './llava_data/train2017/000000219735.jpg'\r\n",
      "Evaluating Epoch 2: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.39it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --sample_size 10000 --batch_size 2 --llm_name Qwen/Qwen2.5-0.5B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c790f487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T16:45:49.497523Z",
     "iopub.status.busy": "2026-02-01T16:45:49.497215Z",
     "iopub.status.idle": "2026-02-01T16:45:55.585040Z",
     "shell.execute_reply": "2026-02-01T16:45:55.584071Z"
    },
    "papermill": {
     "duration": 6.80933,
     "end_time": "2026-02-01T16:45:55.586793",
     "exception": false,
     "start_time": "2026-02-01T16:45:48.777463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/llava-data-10000\n",
      "/kaggle/input/llava-data-10000/llava_data\n",
      "/kaggle/input/llava-data-10000/llava_data/train2017\n",
      "/kaggle/input/llava-instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5105838f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T16:45:56.811418Z",
     "iopub.status.busy": "2026-02-01T16:45:56.811134Z",
     "iopub.status.idle": "2026-02-01T16:45:56.930174Z",
     "shell.execute_reply": "2026-02-01T16:45:56.929531Z"
    },
    "papermill": {
     "duration": 0.732399,
     "end_time": "2026-02-01T16:45:56.931562",
     "exception": false,
     "start_time": "2026-02-01T16:45:56.199163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/kaggle/working/qwen-vlm/llava_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir /kaggle/working/qwen-vlm/llava_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f7a279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T16:45:58.245572Z",
     "iopub.status.busy": "2026-02-01T16:45:58.245260Z",
     "iopub.status.idle": "2026-02-01T16:45:58.364326Z",
     "shell.execute_reply": "2026-02-01T16:45:58.363678Z"
    },
    "papermill": {
     "duration": 0.734307,
     "end_time": "2026-02-01T16:45:58.365719",
     "exception": false,
     "start_time": "2026-02-01T16:45:57.631412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projector_best_qwen2.5-0.5b-instruct_clip-vit-base-patch16.pt\r\n",
      "projector_epoch0_qwen2.5-0.5b-instruct_clip-vit-base-patch16.pt\r\n",
      "projector_epoch1_qwen2.5-0.5b-instruct_clip-vit-base-patch16.pt\r\n",
      "projector_epoch2_qwen2.5-0.5b-instruct_clip-vit-base-patch16.pt\r\n",
      "projector_final_qwen2.5-0.5b-instruct_clip-vit-base-patch16.pt\r\n"
     ]
    }
   ],
   "source": [
    "ls /kaggle/working/qwen-vlm/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbac8122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T16:45:59.691453Z",
     "iopub.status.busy": "2026-02-01T16:45:59.690602Z",
     "iopub.status.idle": "2026-02-01T16:45:59.806537Z",
     "shell.execute_reply": "2026-02-01T16:45:59.805876Z"
    },
    "papermill": {
     "duration": 0.735464,
     "end_time": "2026-02-01T16:45:59.808161",
     "exception": false,
     "start_time": "2026-02-01T16:45:59.072697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/working/qwen-vlm/checkpoints/projector.pt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "cp /kaggle/working/qwen-vlm/checkpoints/projector.pt /kaggle/working/qwen-vlm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f558af4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T16:46:01.142984Z",
     "iopub.status.busy": "2026-02-01T16:46:01.142669Z",
     "iopub.status.idle": "2026-02-01T16:46:01.261589Z",
     "shell.execute_reply": "2026-02-01T16:46:01.260890Z"
    },
    "papermill": {
     "duration": 0.82159,
     "end_time": "2026-02-01T16:46:01.263332",
     "exception": false,
     "start_time": "2026-02-01T16:46:00.441742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llava_instruct_150k.json\r\n"
     ]
    }
   ],
   "source": [
    "ls /kaggle/input/llava-instruct"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9382397,
     "sourceId": 14686845,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9387499,
     "sourceId": 14695009,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8763.678954,
   "end_time": "2026-02-01T16:46:02.199438",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-01T14:19:58.520484",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
